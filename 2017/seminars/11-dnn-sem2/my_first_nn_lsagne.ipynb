{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lecture</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Активации из сетей для классификации, это хорошие признаки для изображений\n",
    "\n",
    "<img src=\"img/act.png\" width=\"800\">\n",
    "\n",
    "\n",
    "## Современные архитектуры очень глубокие , самые модные \n",
    "\n",
    "### VGG (стандартная архитектура, без наворотов)\n",
    "\n",
    "<img src=\"img/vgg.png\" width=\"600\">\n",
    "\n",
    "### ResNet (Shortcut + Batch Normalization)\n",
    " \n",
    "<img src=\"img/resnet.png\" width=\"800\">\n",
    " \n",
    "### GoogleNet (Много раз предсказываем классы на разных уровнях сети)\n",
    "\n",
    " \n",
    "<img src=\"img/gln.png\" width=\"800\">\n",
    "\n",
    "\n",
    "## Чем глубже слой тем более высокоуровневые признаки он детектирует\n",
    "\n",
    "<img src=\"img/feat.png\" width=\"800\">\n",
    "\n",
    "## На практике гораздо проще дообучать уже обученные сети (Fine-Tuning)\n",
    "\n",
    "<img src=\"img/ft.jpg\" width=\"600\">\n",
    "\n",
    "## Dark Magic \n",
    "\n",
    "<img src=\"img/dm.png\" width=\"600\">\n",
    "\n",
    "# Сегодня Theano and Lasagne :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Theano</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install -U https://github.com/Theano/Theano/archive/master.zip\n",
    "pip install -U https://github.com/Lasagne/Lasagne/archive/master.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разминка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### будущий параметр функции -- символьная переменная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = T.scalar('a dimension', dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### рецепт получения квадрата -- орперации над символьными переменным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = T.power(N, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### theano.grad(cost, wrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_result = theano.grad(result, N) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### компиляция функции \"получения квадрата\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_function = theano.function(inputs=[N], outputs=result)\n",
    "gr_function = theano.function(inputs=[N], outputs=grad_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### применение функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заводим np.array x\n",
    "xv = np.arange(-10, 10)\n",
    "\n",
    "# Применяем функцию к каждому x\n",
    "val = map(float, [sq_function(x) for x in xv])\n",
    "\n",
    "# Посичтаем градиент в кажой точке\n",
    "grad = map(float, [gr_function(x) for x in xv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что мы увидим если нарисуем функцию и градиент?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(xv, val, label='x*x')\n",
    "pylab.plot(xv, grad, label='d x*x / dx')\n",
    "pylab.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как оно работает?\n",
    "* почти всё, что есть в numpy есть в theano tensor и называется так же: `np.mean -> T.mean` и так далее...\n",
    "* `theano.function` умеет за одно обновлять `shared` переменные по рецепту в `updates`\n",
    "* Переменные нужно хранить в `shared` переменных, их можно менять после компиляции `theano.shared(np.ones(10))`\n",
    "\n",
    " \n",
    "Ничего не понятно? Сейчас исправим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь сам, LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X_data, y_data = datasets.load_digits(2, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'y метки классов 0 или 1 [форма - %s]:' % (str(y_data.shape)),y[:10]\n",
    "print 'X цифорки вытянутые в вектор [форма - %s]:' % (str(X_data.shape))\n",
    "print X_data[0].reshape((8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# переменные и входы\n",
    "W = <твой код>\n",
    "X = <твой код>\n",
    "y = <твой код>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_y = <предсказание логрегрессии на X (вероятность класса)>\n",
    "loss = <логистическая ошибка, число>\n",
    "grad = <градиент loss по весам модели>\n",
    "updates = {W: <новое значение весов после шага градиентного спуска>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_function = <функция, которая по X и Y возвращает ошибку и обновляет веса>\n",
    "predict_function = <функция, которая по X считает предсказание для y>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for i in range(5):\n",
    "    loss_i = train_function(X_train,y_train)\n",
    "    print ' loss at iter %i:%.4f' % (i, loss_i),\n",
    "    print ' train auc:', roc_auc_score(y_train, predict_function(X_train)),\n",
    "    print ' test auc:', roc_auc_score(y_test, predict_function(X_test))\n",
    "    \n",
    "print (\"resulting weights:\")\n",
    "plt.imshow(W.get_value().reshape(8,-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lasagne</h1>\n",
    "\n",
    "* lasagne - это библиотека для написания нейронок произвольной формы на theano\n",
    "* В качестве демо-задачи выберем то же распознавание чисел, но на большем масштабе задачи, картинки 28x28, 10 цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "print 'X размера', X_train.shape, 'y размера', y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(20, 20))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(X_train[i, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на DenseLayer в lasagne\n",
    "- http://lasagne.readthedocs.io/en/latest/modules/layers/dense.html\n",
    "- https://github.com/Lasagne/Lasagne/blob/master/lasagne/layers/dense.py#L16-L124 \n",
    "- Весь содаржательный код тут https://github.com/Lasagne/Lasagne/blob/master/lasagne/layers/dense.py#L121 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from theano import tensor as T\n",
    "from lasagne.nonlinearities import softmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lasagne import init\n",
    "\n",
    "X, y = T.tensor4('X'), T.vector('y', 'int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так задаётся архитектура нейронки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#входной слой (вспомогательный)\n",
    "net = lasagne.layers.InputLayer(shape=(None, 1, 28, 28), input_var=X)\n",
    "\n",
    "net = lasagne.layers.Conv2DLayer(net, 15, 28, pad='valid', W=init.Constant()) # сверточный слой\n",
    "net = lasagne.layers.Conv2DLayer(net, 10,  2, pad='full', W=init.Constant())  # сверточный слой\n",
    "\n",
    "net = lasagne.layers.DenseLayer(net, num_units=500) # полносвязный слой\n",
    "net = lasagne.layers.DropoutLayer(net, 1.0)         # регуляризатор\n",
    "net = lasagne.layers.DenseLayer(net, num_units=200) # полносвязный слой\n",
    "\n",
    "net = lasagne.layers.DenseLayer(net, num_units=10)  # полносвязный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#предсказание нейронки (theano-преобразование)\n",
    "y_predicted = lasagne.layers.get_output(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#все веса нейронки (shared-переменные)\n",
    "all_weights = lasagne.layers.get_all_params(net)\n",
    "print all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция ошибки и точности будет прямо внутри\n",
    "loss = lasagne.objectives.categorical_accuracy(y_predicted, y).mean()\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#сразу посчитать словарь обновлённых значений с шагом по градиенту, как раньше\n",
    "updates = lasagne.updates.momentum(loss, all_weights, learning_rate=1.0, momentum=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция, делает updates и возвращащет значение функции потерь и точности\n",
    "train_fun = theano.function([X, y], [loss, accuracy], updates=updates)\n",
    "accuracy_fun = theano.function([X, y], accuracy) # точность без обновления весов, для теста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from mnist import iterate_minibatches\n",
    "\n",
    "num_epochs = 10 #количество проходов по данным\n",
    "batch_size = 100 #размер мини-батча\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err, train_acc, train_batches = 0, 0, 0\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc, val_batches = 0, 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print('Epoch %s of %s took' % (epoch + 1, num_epochs))\n",
    "    print('\\t training loss:\\t\\t %.5f' % (train_err / train_batches))\n",
    "    print('\\t train accuracy:\\t %s' % (train_acc / train_batches * 100))\n",
    "    print('\\t validation accuracy:\\t %s' % (val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results: \\n test accuracy:\\t\\t{:.2f} %\".format(test_acc / test_batches * 100))чы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# не забывайте оставлять отзывы \n",
    "# о лекции https://goo.gl/gMeYNL о семинаре https://goo.gl/5hlPD0 :)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
