{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lecture</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Активации из сетей для классификации, это хорошие признаки для изображений\n",
    "\n",
    "<img src=\"img/act.png\" width=\"800\">\n",
    "\n",
    "\n",
    "## Современные архитектуры очень глубокие , самые модные \n",
    "\n",
    "### VGG (стандартная архитектура, без наворотов)\n",
    "\n",
    "<img src=\"img/vgg.png\" width=\"600\">\n",
    "\n",
    "### ResNet (Shortcut + Batch Normalization)\n",
    " \n",
    "<img src=\"img/resnet.png\" width=\"800\">\n",
    " \n",
    "### GoogleNet (Много раз предсказываем классы на разных уровнях сети)\n",
    "\n",
    " \n",
    "<img src=\"img/gln.png\" width=\"800\">\n",
    "\n",
    "\n",
    "## Чем глубже слой тем более высокоуровневые признаки он детектирует\n",
    "\n",
    "<img src=\"img/feat.png\" width=\"800\">\n",
    "\n",
    "## На практике гораздо проще дообучать уже обученные сети (Fine-Tuning)\n",
    "\n",
    "<img src=\"img/ft.jpg\" width=\"600\">\n",
    "\n",
    "## Dark Magic \n",
    "\n",
    "<img src=\"img/dm.png\" width=\"600\">\n",
    "\n",
    "# Сегодня Theano and Lasagne :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Theano</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install -U https://github.com/Theano/Theano/archive/master.zip\n",
    "pip install -U https://github.com/Lasagne/Lasagne/archive/master.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разминка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### будущий параметр функции -- символьная переменная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = T.scalar('a dimension', dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### рецепт получения квадрата -- орперации над символьными переменным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = T.power(N, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### theano.grad(cost, wrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_result = theano.grad(result, N) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### компиляция функции \"получения квадрата\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sq_function = theano.function(inputs=[N], outputs=result)\n",
    "gr_function = theano.function(inputs=[N], outputs=grad_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### применение функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Заводим np.array x\n",
    "xv = np.arange(-10, 10)\n",
    "\n",
    "# Применяем функцию к каждому x\n",
    "val = map(float, [sq_function(x) for x in xv])\n",
    "\n",
    "# Посичтаем градиент в кажой точке\n",
    "grad = map(float, [gr_function(x) for x in xv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что мы увидим если нарисуем функцию и градиент?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'map' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/units.py\u001b[0m in \u001b[0;36mget_converter\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;31m# get_converter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxravel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                     \u001b[0;31m# some elements are not masked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'mask'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8adbac6e7ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x*x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd x*x / dx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mbx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mupdate_units\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \"\"\"\n\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m         \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmunits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/units.py\u001b[0m in \u001b[0;36mget_converter\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 if (not isinstance(next_item, np.ndarray) or\n\u001b[1;32m    157\u001b[0m                     next_item.shape != x.shape):\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/daniilkorbut/anaconda/lib/python3.5/site-packages/matplotlib/units.py\u001b[0m in \u001b[0;36mget_converter\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mthisx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_first_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclassx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mclassx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__class__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'map' has no len()"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e0a2fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(xv, val, label='x*x')\n",
    "pylab.plot(xv, grad, label='d x*x / dx')\n",
    "pylab.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как оно работает?\n",
    "* почти всё, что есть в numpy есть в theano tensor и называется так же: `np.mean -> T.mean` и так далее...\n",
    "* `theano.function` умеет за одно обновлять `shared` переменные по рецепту в `updates`\n",
    "* Переменные нужно хранить в `shared` переменных, их можно менять после компиляции `theano.shared(np.ones(10))`\n",
    "\n",
    " \n",
    "Ничего не понятно? Сейчас исправим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь сам, LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X_data, y_data = datasets.load_digits(2, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y метки классов 0 или 1 [форма - (360,)]: [0 1 0 1 0 1 0 0 1 1]\n",
      "X цифорки вытянутые в вектор [форма - (360, 64)]:\n",
      "[[  0.   0.   5.  13.   9.   1.   0.   0.]\n",
      " [  0.   0.  13.  15.  10.  15.   5.   0.]\n",
      " [  0.   3.  15.   2.   0.  11.   8.   0.]\n",
      " [  0.   4.  12.   0.   0.   8.   8.   0.]\n",
      " [  0.   5.   8.   0.   0.   9.   8.   0.]\n",
      " [  0.   4.  11.   0.   1.  12.   7.   0.]\n",
      " [  0.   2.  14.   5.  10.  12.   0.   0.]\n",
      " [  0.   0.   6.  13.  10.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print ('y метки классов 0 или 1 [форма - %s]:' % (str(y_data.shape)),y_data[:10])\n",
    "print ('X цифорки вытянутые в вектор [форма - %s]:' % (str(X_data.shape)))\n",
    "print (X_data[0].reshape((8, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переменные и входы\n",
    "W = theano.shared(np.ones(X_data.shape[1]))\n",
    "X = T.matrix(\"float64\")\n",
    "y = T.vector(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_y = T.nnet.sigmoid(T.dot(X, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -T.mean(y * T.log(predicted_y) + (1 - y) * T.log(1 - predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad = T.grad(loss, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = {\n",
    "    W:W - learning_rate*grad\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_function = theano.function([X, y], loss, updates=updates)\n",
    "predict_function = theano.function([X], predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss at iter 0:118.2993\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 1:109.9236\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 2:101.5479\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 3:93.1722\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 4:84.7964\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 5:76.4207\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 6:68.0450\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 7:59.6693\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 8:51.2936\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 9:42.9179\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 10:34.5422\n",
      " train auc: 0.5\n",
      " test auc: 0.5\n",
      " loss at iter 11:26.1665\n",
      " train auc: 0.536496350365\n",
      " test auc: 0.524390243902\n",
      " loss at iter 12:17.7908\n",
      " train auc: 0.784671532847\n",
      " test auc: 0.756097560976\n",
      " loss at iter 13:9.4585\n",
      " train auc: 0.956204379562\n",
      " test auc: 0.926829268293\n",
      " loss at iter 14:3.0726\n",
      " train auc: 0.996350364964\n",
      " test auc: 0.987804878049\n",
      " loss at iter 15:1.1625\n",
      " train auc: 0.996350364964\n",
      " test auc: 0.987804878049\n",
      " loss at iter 16:0.5313\n",
      " train auc: 0.996350364964\n",
      " test auc: 0.987804878049\n",
      " loss at iter 17:0.3258\n",
      " train auc: 0.996350364964\n",
      " test auc: 1.0\n",
      " loss at iter 18:0.2449\n",
      " train auc: 0.996350364964\n",
      " test auc: 1.0\n",
      " loss at iter 19:0.1988\n",
      " train auc: 0.996350364964\n",
      " test auc: 1.0\n",
      " loss at iter 20:0.1703\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 21:0.1520\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 22:0.1390\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 23:0.1290\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 24:0.1209\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 25:0.1140\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 26:0.1080\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 27:0.1028\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 28:0.0980\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 29:0.0937\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 30:0.0898\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 31:0.0861\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 32:0.0827\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 33:0.0794\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 34:0.0763\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 35:0.0733\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 36:0.0705\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 37:0.0677\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 38:0.0651\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 39:0.0625\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 40:0.0601\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 41:0.0578\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 42:0.0556\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 43:0.0536\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 44:0.0517\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 45:0.0499\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 46:0.0483\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 47:0.0468\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 48:0.0454\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 49:0.0441\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 50:0.0430\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 51:0.0419\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 52:0.0409\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 53:0.0400\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 54:0.0391\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 55:0.0383\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 56:0.0375\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 57:0.0368\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 58:0.0361\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 59:0.0355\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 60:0.0349\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 61:0.0343\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 62:0.0337\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 63:0.0332\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 64:0.0327\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 65:0.0321\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 66:0.0316\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 67:0.0312\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 68:0.0307\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 69:0.0302\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 70:0.0298\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 71:0.0293\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 72:0.0289\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 73:0.0284\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 74:0.0280\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 75:0.0276\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 76:0.0272\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 77:0.0268\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 78:0.0264\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 79:0.0259\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 80:0.0255\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 81:0.0251\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 82:0.0248\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 83:0.0244\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 84:0.0240\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 85:0.0236\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 86:0.0232\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 87:0.0228\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 88:0.0224\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 89:0.0221\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 90:0.0217\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 91:0.0213\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 92:0.0209\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 93:0.0206\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 94:0.0202\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 95:0.0198\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 96:0.0194\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 97:0.0191\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 98:0.0187\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      " loss at iter 99:0.0183\n",
      " train auc: 1.0\n",
      " test auc: 1.0\n",
      "resulting weights:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1104c9710>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAAD8CAYAAADwpviIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCsJLCKKlQQWEcVKAouIYiWBRUSx/j/0Z6/NLc0r9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1102de9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for i in range(100):\n",
    "    loss_i = train_function(X_train,y_train)\n",
    "    print (' loss at iter %i:%.4f' % (i, loss_i),)\n",
    "    print (' train auc:', roc_auc_score(y_train, predict_function(X_train)),)\n",
    "    print (' test auc:', roc_auc_score(y_test, predict_function(X_test)))\n",
    "    \n",
    "print (\"resulting weights:\")\n",
    "plt.imshow(W.get_value().reshape(8,-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lasagne</h1>\n",
    "\n",
    "* lasagne - это библиотека для написания нейронок произвольной формы на theano\n",
    "* В качестве демо-задачи выберем то же распознавание чисел, но на большем масштабе задачи, картинки 28x28, 10 цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X размера (50000, 1, 28, 28) y размера (50000,)\n"
     ]
    }
   ],
   "source": [
    "from mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "print ('X размера', X_train.shape, 'y размера', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAACqCAYAAAA6El8nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAiAE2gQAAAAAAAGLg/wFTjxVjkfuXcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11049de80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(20, 20))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(X_train[i, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на DenseLayer в lasagne\n",
    "- http://lasagne.readthedocs.io/en/latest/modules/layers/dense.html\n",
    "- https://github.com/Lasagne/Lasagne/blob/master/lasagne/layers/dense.py#L16-L124 \n",
    "- Весь содаржательный код тут https://github.com/Lasagne/Lasagne/blob/master/lasagne/layers/dense.py#L121 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from theano import tensor as T\n",
    "from lasagne.nonlinearities import softmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lasagne import init\n",
    "\n",
    "X, y = T.tensor4('X'), T.vector('y', 'int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так задаётся архитектура нейронки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#входной слой (вспомогательный)\n",
    "net = lasagne.layers.InputLayer(shape=(None, 1, 28, 28), input_var=X)\n",
    "\n",
    "net = lasagne.layers.Conv2DLayer(net, 10, 3, W=init.Normal()) # сверточный слой\n",
    "#net = lasagne.layers.Conv2DLayer(net, 10,  2, pad='full', W=init.Normal())  # сверточный слой\n",
    "net = lasagne.layers.DenseLayer(net, num_units=50) # полносвязный слой\n",
    "net = lasagne.layers.DropoutLayer(net, 0.5)         # регуляризатор\n",
    "net = lasagne.layers.DenseLayer(net, num_units=10) # полносвязный слой\n",
    "\n",
    "net = lasagne.layers.DenseLayer(net, nonlinearity=lasagne.nonlinearities.softmax, num_units=10)  # полносвязный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#предсказание нейронки (theano-преобразование)\n",
    "y_predicted = lasagne.layers.get_output(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b, W, b]\n"
     ]
    }
   ],
   "source": [
    "#все веса нейронки (shared-переменные)\n",
    "all_weights = lasagne.layers.get_all_params(net)\n",
    "print (all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция ошибки и точности будет прямо внутри\n",
    "loss = lasagne.objectives.categorical_crossentropy(y_predicted, y).mean()\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#сразу посчитать словарь обновлённых значений с шагом по градиенту, как раньше\n",
    "updates = lasagne.updates.momentum(loss, all_weights, learning_rate=0.5, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция, делает updates и возвращащет значение функции потерь и точности\n",
    "train_fun = theano.function([X, y], [loss, accuracy], updates=updates)\n",
    "accuracy_fun = theano.function([X, y], accuracy) # точность без обновления весов, для теста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10 took\n",
      "\t training loss:\t\t 2.30816\n",
      "\t train accuracy:\t 11.188\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 2 of 10 took\n",
      "\t training loss:\t\t 2.30907\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 3 of 10 took\n",
      "\t training loss:\t\t 2.31777\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 4 of 10 took\n",
      "\t training loss:\t\t 2.30907\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 5 of 10 took\n",
      "\t training loss:\t\t 2.30907\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 6 of 10 took\n",
      "\t training loss:\t\t 2.30939\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 7 of 10 took\n",
      "\t training loss:\t\t 2.30907\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 8 of 10 took\n",
      "\t training loss:\t\t 2.30907\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 9 of 10 took\n",
      "\t training loss:\t\t 2.30907\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n",
      "Epoch 10 of 10 took\n",
      "\t training loss:\t\t 2.30907\n",
      "\t train accuracy:\t 10.438\n",
      "\t validation accuracy:\t 10.3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from mnist import iterate_minibatches\n",
    "\n",
    "num_epochs = 10 #количество проходов по данным\n",
    "batch_size = 100 #размер мини-батча\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err, train_acc, train_batches = 0, 0, 0\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc, val_batches = 0, 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print('Epoch %s of %s took' % (epoch + 1, num_epochs))\n",
    "    print('\\t training loss:\\t\\t %.5f' % (train_err / train_batches))\n",
    "    print('\\t train accuracy:\\t %s' % (train_acc / train_batches * 100))\n",
    "    print('\\t validation accuracy:\\t %s' % (val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results: \\n test accuracy:\\t\\t{:.2f} %\".format(test_acc / test_batches * 100))чы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# не забывайте оставлять отзывы \n",
    "# о лекции https://goo.gl/gMeYNL о семинаре https://goo.gl/5hlPD0 :)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
